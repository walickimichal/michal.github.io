%\documentstyle[a4wide]{article}
%\makeatletter
%\show\
\renewcommand{\not}[1]{\mathbin {\mathpalette\c@ncel#1}}
\makeatother

\newtheorem{CLAIM}{Proposition}[section]
\newtheorem{COROLLARY}[CLAIM]{Corollary}
\newtheorem{THEOREM}[CLAIM]{Theorem}
\newtheorem{LEMMA}[CLAIM]{Lemma}
\newcommand{\MyLPar}{\parsep -.2ex plus.2ex minus.2ex\itemsep\parsep
   \vspace{-\topsep}\vspace{.5ex}}
\newcommand{\MyNumEnv}[1]{\parskip 0pt\partopsep 0pt\trivlist \refstepcounter 
   {CLAIM}\item [\hskip \labelsep {\bf #1\ \theCLAIM\ }]\sf \ignorespaces}
\newenvironment{DEFINITION}{\MyNumEnv{Definition}}{\par\addvspace{1ex}}
\newenvironment{EXAMPLE}{\MyNumEnv{Example}}{\nopagebreak\finish}
\newenvironment{PROOF}{{\bf Proof.}}{\nopagebreak\finish}
\newcommand{\finish}{\hspace*{\fill}\nopagebreak 
     \raisebox{-1ex}{$\Box$}\hspace*{1em}\par\addvspace{1ex}}
\renewcommand{\abstract}[1]{\noindent {\small{\bf Abstract. }#1}}
\newcommand{\B}[1]{{\rm I\hspace{-.2em}#1}}
\newcommand{\Nat}{{\B N}}
\renewcommand{\c}[1]{{\cal #1}}
\newcommand{\Funcs}{{\cal F}}
%\newcommand{\Terms}{{\cal T}(\Funcs,\Vars)}
\newcommand{\Terms}[1]{{\cal T}(#1)}
\newcommand{\Vars}{{\cal V}}

\newcommand{\Incl}{\mathbin{\prec}}
\newcommand{\Cont}{\mathbin{\succ}}
\newcommand{\Int}{\mathbin{\frown}}
\newcommand{\Seteq}{\mathbin{\asymp}}
\newcommand{\Eq}{\mathbin{\approx}}

\newcommand{\notEq}{\mathbin{\Not\approx}}
\newcommand{\notIncl}{\mathbin{\Not\prec}}
\newcommand{\notCont}{\mathbin{\Not\succ}}
\newcommand{\notInt}{\mathbin{\Not\frown}}
\newcommand{\notSeteq}{\mathbin{\Not\asymp}}
%\renewcommand{\neq}{\mathbin{\not=}}

\newcommand{\red}[2]{\mbox{\sf red}(#1,#2)}
\newcommand{\redC}[2]{\mbox{\sf red}({\cal #1},#2)}


\newcommand{\eh}{\mathbin{\vdash\!\!\vdash}}
%\newcommand{\eh}{\mathbin{\vdash\!\!\!\vdash}}
\newcommand{\noteh}{\mathbin{\Not{\eh}}}
\newcommand{\forc}[2]{\mathrel{#1 \eh #2}}
\newcommand{\notforc}[2]{\mathrel{#1 \noteh #2}}
%\newcommand{\forc}[2]{\mbox{\sf forc}(#1,#2)}

\newcommand{\Seq}{\mathrel{\mapsto}}
\newcommand{\Ord}{\mathbin{\rightarrow}}
\newcommand{\M}[1]{\mathbin{\mathord{#1}^m}}
\newcommand{\Mset}[1]{{\cal M}(#1)}
\newcommand{\interpret}[1]{[\![#1]\!]^{A}_{\rho}}
\newcommand{\Interpret}[1]{[\![#1]\!]^{A}}
\newcommand{\Comp}[2]{#1\diamond#2}
\newcommand{\Repl}[2]{\mbox{\sf Repl}(#1,#2)}
\newcommand{\Sup}{\mbox{\sf Sup}}
\newcommand\SS[1]{{\cal S}^{#1}}
\newcommand{\To}[1]{\mathbin{\stackrel{#1}{\longrightarrow}}}
\newcommand{\TTo}[1]{\mathbin{\stackrel{#1}{\Longrightarrow}}}
\newcommand{\oT}[1]{\mathbin{\stackrel{#1}{\longleftarrow}}}
\newcommand{\oTT}[1]{\mathbin{\stackrel{#1}{\Longleftarrow}}}
\newcommand{\es}{\emptyset}
\newcommand{\C}[1]{\mbox{$\cal #1$}}
\newcommand{\Mb}[1]{\mbox{#1}}
\newcommand{\<}{\langle}
\renewcommand{\>}{\rangle}
\newcommand{\Def}{\mathrel{\stackrel{\mbox{\tiny def}}{=}}}
\newcommand{\impl}{\mathrel\Rightarrow}
\newcommand{\then}{\mathrel\Rightarrow}
\newcommand{\List}[3]{#1_{1}#3\ldots#3#1_{#2}}
\newcommand{\prule}[2]{{\displaystyle #1 \over \displaystyle#2}}
\newcounter{ITEM}
\newcommand{\newITEM}[1]{\gdef\ITEMlabel{ITEM:#1-}\setcounter{ITEM}{0}}
\makeatletter
\newcommand{\Not}[1]{\mathbin {\mathpalette\c@ncel#1}}
\def\l@bel#1${\edef\@currentlabel{(\roman{ITEM})}\label{#1}}
\newcommand{\ITEM}[2]{\par\addvspace{.7ex}\noindent
   \refstepcounter{ITEM}\expandafter\l@bel\ITEMlabel#1${\advance\linewidth-2em
   \hskip2em \parbox{\linewidth}{\hskip-2em {\rm\bf \@currentlabel\
   }\ignorespaces #2}}\par \addvspace{.7ex}\noindent\ignorespaces}
\def\R@f#1${\ref{#1}}
\newcommand{\?}[1]{\expandafter\R@f\ITEMlabel#1$}
\makeatother
\newcommand{\PROOFRULE}[2]{\trivlist\item[\hskip\labelsep {\bf #1}]#2\par
  \addvspace{1ex}\noindent\ignorespaces}
\newenvironment{clauses}{\begin{array}{r@{.\ \ }r@{\;\Seq\;}l}}{\end{array}}
\newcommand{\Cs}{\varepsilon}
\newcommand{\const}[3]{\Cs_{\scriptscriptstyle#2}(#1,#3)}
\newcommand{\Ein}{\sqsubset}%
\newcommand{\Eineq}{\sqsubseteq}%

%\voffset -2cm
\begin{document}

\title{Reasoning and Rewriting with Set-Relations I: \\Ground Completeness}

%changes:  interlines spaces decreased
\author{ {\it Valentinas Kriau\v ciukas\thanks{Both authors gratefully 
acknowledge the financial support received from the Norwegian Research Council.}}\\[-.5ex]
\small Department of Mathematical Logic\\[-.5ex]
\small Institute of Mathematics and Informatics\\[-.5ex]
\small Vilnius, LITHUANIA\\[-.5ex]
\footnotesize valentinas.kriauciukas@mlats.mii.lt 
\and 
{\it Micha{\l} Walicki\/\(^\ast\)}\\[-.5ex]
\small Department of Computer Science\\[-.5ex]
\small University of Bergen\\[-.5ex]
\small Bergen, NORWAY\\[-.5ex]
\footnotesize michal@ii.uib.no}

\maketitle
\abstract {The paper investigates reasoning with set-relations: intersection, 
inclusion and identity of 1-element sets. A language is introduced which, 
interpreted in a multialgebraic semantics, allows one to specify such 
relations. An inference system is given and shown sound and 
refutationally ground-complete for 
a particular proof strategy which selects only maximal literals from the premise 
clauses. Each of the introduced set-relations satisfies only two among the 
three properties of the equivalence relations - we study rewriting with such 
non-equivalence relations and point out differences from the equational case. 
As a corollary of the main ground-completeness theorem we obtain 
ground-completeness of the introduced rewriting technique.}

\section{Introduction}

Reasoning with sets becomes an important issue in different areas of computer 
science. Its relevance can be noticed in constraint and logic programming e.g. 
\cite{SD,DO,Jay,Sto}, in algebraic approach to nondeterminism e.g. 
\cite{HusB,PS1,MW}, in term rewriting e.g. \cite{LA,Kap,HusB}.

Our interest in the set concepts originates from an earlier study of 
specifications of nondeterministic operations. Such operations are naturally 
modelled as set-valued functions. The semantic structures serving this purpose 
- {\em multialgebras} - generalize the traditional algebras allowing operations 
which, for a given argument, return not necessarily a single value but a set of 
values (namely, the set of all possible values returned by an arbitrary 
application of the operation). In \cite{MW,Mich} we defined a specification 
language using set-relations and its multialgebraic semantics. The 
set-relations we considered were: inclusion, intersection and identity of 
1-element sets. The first two are the usual set relations. Inclusion allows one 
to define set equality which, for that reason, is not included in the language. 
The third relation is particularly important: it provides the syntactic 
\mbox{means}
of distinguishing between sets and their elements, and is indispensable for 
obtaining a complete reasoning system. Such a system is also given in the above 
works.

In the present paper we use the same set-relations but introduce a new 
reasoning system. It is less general than the earlier one - we are studying only 
the ground case - but it is much more prone to automation. Rewriting with 
non-congruence relations becomes also an issue of increasing importance. The 
set-relations we are considering are not even equivalences: equality is 
symmetric and transitive (but not reflexive), inclusion is reflexive and 
transitive (but not symmetric) and intersection is reflexive and symmetric (but 
not transitive). We study the rewriting proofs in the presence of these 
relations generalizing several classical notions (critical pair, confluence, 
rewriting proof) to the present context. Our results on rewriting extend
bi-rewriting of Levy and Agusti \cite{LA} in that we consider three different 
set-relations. We also take a step beyond the framework of Bachmair and 
Ganzinger \cite{BG249} in that we study more general composition of relations 
than chaining of transitive relations.

Section~\ref{se:nd-specs} defines the syntax and the multialgebraic semantics 
of the language and lists some basic properties of the set-relations. 
Section~\ref{se:reasoning} introduces the reasoning system \C I, ordering of 
words and specifies the {\em maximal literal} proof strategy for using \C I.
Section~\ref{se:rewrite} discusses term rewriting with the introduced 
set-relations. In section~\ref{se:completeness} we prove the main theorem - refutational
ground completeness of \C I with the maximal literal strategy and, as a simple 
corollary, ground completeness of rewriting.

%changes
The present paper is an improved and shortened version of the report \cite{KW}.
Because of the space limitations, we only include the proofs of the central 
lemmas and theorems.

\section{Specifications of set-relations} \label{se:nd-specs}

% \subsection{Syntax}
Specifications are written using a finite set of function symbols $\Funcs$
having arity $ar:\Funcs\to \Nat$.\footnote
{We are treating only the unsorted case --
extension to many sorts is straightforward.}
A symbol $f\in\Funcs^0$ %with $ar(f)=0$ is
is called a {\em constant}.  Only ground case is considered here, and we do not
introduce any variables.  We denote by $\Terms\Funcs$ the set of all (ground)
terms.  There are only three atomic forms using binary predicates: {\em
equation} $s\Eq t$, {\em inclusion} $s\Incl t$ and {\em intersection} $s\Int
t$. A {\em specification} is a set of {\em clauses}
%changes
--- finite sets of {\em
literals}, where a {\em literal} is an atom or a negated atom written \(\neg 
a\).
%changes
%CHANGE
 (In \cite{MW,Mich} a 
restricted language is used, allowing only negated intersections, positive 
inclusions and equations in clauses.) We will usually write negated atoms 
explicitly as $s\notEq t$, $s\notIncl t$ and $s\notInt t$, and 
assume \(\neg(\neg a)=a\).
%
By
{\em words} we will mean the union of the sets of terms, literals and
clauses.  We will write $u[s]_p$ to denote that a term $s$ is a subterm of a
term $u$ at a position $p$. Often the position will be omitted for the sake of
simplicity.
%CHANGE  - removed from here and moved to the begining of Section 5.
%

Syntactic expressions of the language are interpretated in {\em multialgebras}
\cite{Kap,Hus,Mich}.
\begin{DEFINITION}
An $\Funcs$-{\em multialgebra} $A$ is a tuple \(\<S^A,\Funcs^A\>\) where $S^A$
is a non empty {\em carrier} set, and $\Funcs^A$ is a set of set-valued functions
\(f^A: (S^A)^{ar(f)}\to\C P^+(S^A)\), where \(f\in \Funcs\), and \(\C P^+(S^A)\)
is the power-set of \(S^A\) with the empty set excluded.
\end{DEFINITION}
Defining the meaning of the words we follow \cite{MW,Mich}.
\begin{DEFINITION} \label{def:semantics}
An interpretation
\(\Interpret d\) of any expression $d$ of the language is defined as follows: 
\begin{itemize}\MyLPar
\item \(\Interpret c \Def c^A\), if $c$ is a constant;
\item \(\Interpret{f(\List tn,)} \Def \bigcup\{f^A(\List\alpha n,):
  \alpha_i\in\Interpret {t_i}\}\) 
for any \(f\in \Funcs^n\) and \(\{\List
  tn,\}\subset \Terms\Funcs\);
\item \(\Interpret{s\Eq t}\) is true if \(\Interpret s=\Interpret
  t=\{\alpha\}\) for some $\alpha\in S^A$, and false otherwise;
\item \(\Interpret{s\Incl t}\) is true if \(\Interpret s\subseteq\Interpret
  t\), and false otherwise;
\item \(\Interpret{s\Int t}\) is true if \(\Interpret s\cap \Interpret
  t \Not = \es\), and false otherwise;
\item for an atom $a$, \(\Interpret{\neg a}\) is true if \(\Interpret{a}\) 
 is false, and is false otherwise;
\item \(\Interpret{\List an,}\) is true if some
  \(\Interpret{a_i}\) is true, and false otherwise.
% or some \(\Interpret{b_i}\) is true, and false  otherwise.
% (so, empty clause is always false). 
\end{itemize}
\end{DEFINITION}
% We say that a multialgebra $A$ {\em satisfies} an atom $a$ (a clause $C$) if
% \(\Interpret a\) (respectively, \(\Interpret C\)) is true, and $A$ {\em
% satisfies} a specification \C S if it satisfies all clauses in \C S.
Definition~\ref {def:semantics} implies that for each \(f\in \Funcs\), \(f^A\)
is \(\subseteq\)-monotone (because it is defined by pointwise extension).
Interpretation of a constant $c$ is, according to the definition of
multialgebra, a non-empty set. Observe also that equality is not reflexive ---
\(t\Eq t\) is not true in general. A term $t$ for which this equality is true
is called {\em deterministic} because then it has only one possible value. The
equality is merely a symmetric and transitive relation. An inclusion \(s\Incl
t\) means that the term $s$ has the value set which is included in the value
set of $t$. This relation is a partial preorder --- it is transitive and
reflexive, but not symmetric. The intersection is reflexive (because of
nonemptiness of term values) and symmetric, but lacks the transitivity
property. Thus each of these relations satisfies two of the three properties
of equivalence relations.  Now we present some other properties of these
relations.\\[8pt]

\subsection{Basic properties of literals}

The following relation expresses equality of term value sets, and is the usual
 interpretation of equality
 in the set-valued approach to nondeterminism \cite{PS1,Kap}. 
\MyLPar \begin{equation}\MyLPar \label{eq:Seteq-definition}
s\Seteq t\Def s\Incl t\land s\Cont t.
\end{equation}
As can be expected, it does not increase 
expressibility and therefore is not used in the language.
For a discussion of the intended meaning and difference 
between `$\Eq$' and `$\Seteq$' in the context of nondeterminism 
see \cite{MW,Mich}. 

The positive, resp. negative, relations are totally ordered by strength:
\MyLPar\begin{equation}\MyLPar \label{eq:rel-order}
u\Eq v \impl u \Seteq v \impl u\Incl v \impl u\Int v
\hspace{2em} and \hspace{2em}
 u\notEq v \Leftarrow u \notSeteq v \Leftarrow
 u\notIncl v \Leftarrow u\notInt v 
\end{equation}

%CHANGE
 The following two lemmas present the subterm replacement and
composition (chaining) properties. Replacement of
``equals by equals'' occurs only in the case of two of the four relations.
Nevertheless these properties will allow us later to develop techniques of
 term-rewriting. 

\begin{LEMMA}[Replacement] \label{le:replacement}
The following properties hold for the introduced predicates:

\(s\Eq t \impl   u[s]_p \Seteq  u[t]_p, \ \ 
s\Seteq t  \impl  u[s]_p \Seteq  u[t]_p, \ \ 
s\Incl t  \impl  u[s]_p \Incl  u[t]_p, \ \   
s\Int t  \impl  u[s]_p \Int  u[t]_p.\) 
\end{LEMMA}

%The next lemma describes possibilities of {\em chaining} or {\em
%composing} the introduced relations.  Because of quite a big number of cases we
%present results in the form of table. 
\begin{LEMMA} \label{le:composition}
The introduced predicates satisfy the composition properties, giv\-en in
Table~\ref {tbl:composition}.\vspace{-2ex}
\begin{table}[hbt]\MyLPar
\[\begin{array}{|c||c|c|c|c|c|c|c|c|}
\hline
          & s\Eq u   & s\Incl u & s\Cont u & s\Int u  
& s\notEq u   & s\notIncl u & s\notCont u & s\notInt u\\
\hline \hline
s\Eq t    & t\Eq u   & t\Incl u & t\Eq u   & t\Incl u 
& t\notCont u & t\notInt u  & t\notCont u & t\notInt u\\
\hline 
s\Incl t  & t\Cont u & t\Int u  & t\Cont u & t\Int u  
& t\notEq u   & t\notIncl u & t\notEq u   & t\notIncl u \\
\hline 
s\Cont t  & t\Eq u   & t\Incl u & -        & -        
& -           &    -        & t\notCont u & t\notInt u\\
\hline 
s\Int t   & t\Cont u & t\Int u  & -        & -        
& -           &    -        & t\notEq u   & t\notIncl u\\
\hline 
\end{array}\]\MyLPar
\caption{Rules for atom composition} \label{tbl:composition}\vspace{-3ex}
\end{table}
\end{LEMMA}
%
For convenience we will write the
partial function coded in this table as \(\Comp\oplus\otimes=\odot\), meaning
that $\odot$ is the strongest relation obtained by composing \(\oplus\) and
\(\otimes\) for any terms, {\em i.e.}:
\(\Comp\oplus\otimes=\odot\iff(s\oplus t\land t\otimes u\impl s\odot u)\) 
for any terms $s,t,u$.
Note that the table defines only the strongest
composite of the arguments. Because of the ordering (\ref{eq:rel-order}) 
the fact that, for instance, \(\Comp\Eq\notInt=\notInt\)
will imply that also \(\notIncl\) can be obtained from composing \(\Eq\) and 
\(\notInt\).

Composition of negative and positive atoms is symmetric to the composition
of the positive and the negative ones given in the table. Composition of
two negative atoms does not allow one to draw any conclusion and therefore
is not mentioned at all.
%
\begin{LEMMA} \label {le:composition-transitivity}
The composition function \(\Comp\_\_\) is transitive. 
\end{LEMMA}
%
The next lemma is an easy corollary of the two previous lemmas, 
but it is important because it describes the situation known from 
term rewriting as a {\em critical peak} \cite{Der} and is related 
with generation of {\em critical pairs}.
%
\begin{LEMMA} \label{le:replacement-in-atoms}
The defined predicates satisfy the replacement rules for atoms given in
Table~\ref {tbl:replacement}.\vspace{-2ex}
\begin{table}[hbt]
\[\begin{array}{|c||c|c|c|c|c|c|c|c|}
\hline
          & u[s]\Eq v   & u[s]\Incl v & u[s]\Cont v & u[s]\Int v & u[s]\notEq v & u[s]\notIncl v & u[s]\notCont v & u[s]\notInt v\\
\hline
\hline
s\Eq t    & u[t]\Eq v   & u[t]\Incl v & u[t]\Cont v & u[t]\Int v & u[t]\notEq v & u[t]\notIncl v & u[t]\notCont v & u[t]\notInt v\\
\hline
s\Incl t  & u[t]\Cont v & u[t]\Int v  & u[t]\Cont v & u[t]\Int v & u[t]\notEq v & u[t]\notIncl v & u[t]\notEq v & u[t]\notIncl v \\
\hline
s\Cont t  & u[t]\Eq v & u[t]\Incl v & -  & - & -  & - & u[t]\notCont v & u[t]\notInt v \\
\hline
s\Int t   & u[t]\Cont v & u[t]\Int v  & -  & - & -  & -  & u[t]\notEq v & u[t]\notIncl v \\
\hline 
\end{array}\]
\caption{Rules for term replacement in atoms} 
\label{tbl:replacement}\vspace{-3ex}
\end{table}
\end{LEMMA}

The content of this table is also encoded as a partial function:
\(\Repl\oplus\otimes=\odot\iff(s\oplus t\land u[s]_p\otimes v\impl u[t]_p\odot v)\) 
for any terms $s,t,u,v$ and position $p$ at $u$.
%%%%%%%% changes
% CHANGE

The two tables differ in predicate signs at four places --- 1:3 - 1:6
(row 1, columns 3 through 6), where the relation resulting from
Table~\ref{tbl:composition} is stronger than the one from
Table~\ref{tbl:replacement}.  These cases must be distinguished when the 
superposition rule (see below) is applied. Therefore we introduce the
function \(\Sup(s,t,\oplus,\otimes)\), which will select the appropriate
table. Its 
value is \(\Comp\oplus\otimes\) in the
case \(s=t\), and \(\Repl\oplus\otimes\), otherwise.

\section{The Inference System} \label{se:reasoning}

% \subsection{Proof rules}
The following set of rules was constructed in analogy to the inference
systems for first-order predicate calculus with equality \cite{BG,S-A}.
However, there are some additional restrictions due to the composition laws
as compared with the equational case.
Very similar rules are presented in \cite{BG249} for transitive relations.
 
\PROOFRULE{Reflexivity resolution}{\quad \(\prule{C, s\oplus s }{C}\),
where \(\oplus\in\{\notIncl,\notCont,\notInt\}\).}

\PROOFRULE{Superposition}{\quad \(\prule
{C,s\oplus t \qquad D,u[s]_p\otimes v}{C,D,u[t]_p\odot v}\),
where
%%changes
  \(\odot=\Sup(s,u[s]_p,\oplus,\otimes)\).}

% changes: have you changed the name of this rule? 
\PROOFRULE{%Contextual factoring
Compositionality resolution}{\quad \(\prule
{C,s\oplus t \qquad D,s\odot u}{C,t\otimes u,s\odot u}\),
where \(\odot = \Comp{\oplus^{-1}}{\neg\otimes}\). }
%CHANGE - you had \oplus^{-s} and I changed it to ^{-1}

The analogous rule for equality called {\em equality factoring} \cite{BG,S-A}
is a special case of our rule when both premise clauses coincide. In 
\cite{BG249} analogous rule is called {\em transitivity resolution}.

Let $\C I$ denote the inference system consisting of the above rules. 
\begin{THEOREM} \label{th:soundness}
The inference system $\C I$ is sound.
\end{THEOREM}
\begin{PROOF}
Soundness of reflexivity resolution follows from reflexivity of
 `$\Incl$' and `$\Int$'. 
Soundness of superposition is a direct consequence of the replacement
and composition laws (Lemmas~\ref{le:replacement-in-atoms}, \ref{le:composition}).
Soundness of the
compositionality
rule is based on the following short deduction. Suppose that the first premise 
clause and the implication
\(s\oplus t \land \neg(t\otimes u)\impl s\odot u\)
both are true. The later is equivalent to
\(s\oplus t \impl t\otimes u \lor s\odot u \).
A single application of the (usual) resolution rule gives the conclusion of the 
rule. The second premise clause is not used in this step --- it only shows the
goal atom.

\end{PROOF}

\subsection{Ordering of words and the proof strategy}

Various orderings of terms and atoms are used extensively in the study of 
automated deduction. We will apply such an ordering to define a more specific
proof strategy for the system $\C I$, to study the possibility of rewriting
wrt. the introduced predicates and, finally, to define the model in the
completeness proof. We assume the existence of 
a {\em simplification ordering} `$>$' \cite{Der} on ground terms which is
{\em total} (\(\forall s\Not=t\in\Terms\Funcs : s>t\lor t>s\)), 
{\em well-founded} (\(\forall t\in\Terms\Funcs : \{s:s<t\}\) is finite), 
{\em monotone} (\(\forall u,s,t\in\Terms\Funcs :s>t\Rightarrow u[s]>u[t]\)) 
and 
%CHANGE
{\em increasing} (\(\forall s\in\Terms\Funcs : u[s]\Not= s \Rightarrow u[s]>s\)).
Ordering of other words is defined by the {\em multiset extension} \cite{DM} of this
ordering.
Let
$\Mset T$ denote the set of all finite multisets of elements from $T$. Each
element of $\Mset T$ can be represented by a function \(\beta:T\to \Nat\)
such that \(\beta\equiv 0\) except for some finite number of elements of $T$.
\(\beta(d)\) is a number of copies of $d$ in the multiset $\beta$.
\begin{DEFINITION} \label{def:multiset-ordering}
For an ordering `$\Ord$' on a given set $T$, an ordering `\(\M\Ord\)' on the
set \(\Mset T\) is a {\em multiset extension} of `$\Ord$', if
\[\beta\M\Ord\gamma\iff\forall d\in  T\,\exists c\in T\/ \left((\beta(c)>\gamma(c)
\land (\beta(d)\geq \gamma(d) \lor c\Ord d)\right).\]
\end{DEFINITION}
In the particular case of total ordering of $T$,
% \[T=\{t_1\Ord t_2\Ord\cdots\},\] 
which is the only one considered here, \(\alpha\M\Ord\beta\) 
means that there is some $c\in T$ such that:
\(\alpha(c)>\beta(c)\land \forall d\Ord c\; \alpha(d)=\beta(d).\)
This is a lexicographic ordering comparing biggest components first. In the
general case it is known \cite{DM} that `$\M\Ord$' is total if `$\Ord$' is
total and `$\M\Ord$' is well-founded if `$\Ord$' is well-founded.

% \subsubsection{Ordering of atoms and clauses}
Writing a literal $s\oplus t$, we indicate that \(s\geq 
t\). It explains why both
signs `$\Incl$' and  `$\Cont$' are used. This rule, of course, is not applied to the
conclusions of the proof rules. We assume that any
term is bigger than any predicate symbol.
A stronger positive predicate is bigger than a weaker one, the order between 
negative predicates is reversed, and all negative predicates are bigger than 
the positive ones:
 \begin{equation} \label{eq:predicate-order}
\notEq\ >\ \notIncl\ >\ \notCont\ >\ \notInt \ >\ \Eq\ >\ \Incl\ >\ \Cont\ >\ \Int.
 \end{equation}
By analogy with the commonly used approach in equational reasoning, we
identify literals with multisets.
%changes
A literal
$s\oplus t$ is represented by the multiset
\(\{\{s,\oplus\}, \{t,\oplus^{-1}\}\}\), 
% and negation of this atom by the multiset 
% \(\{\{s,s,\oplus\}, \{t,t,\oplus^{-1}\}\}.\) 
%This distinction  makes the negated form of an atom
%bigger than the atom itself. Even more, the negated atom is bigger than
%any atom with the same maximal term. 
The ordering of the predicates will make the negated form of an atom bigger
than the atom itself.

The ordering of literals is the twofold extension of `$<$' because each
literal is a multiset of two multisets. The biggest literal in a clause $C$ w.r.t.
this ordering is denoted by \(\max(C)\).  Clauses are compared as multisets of
literals, so their ordering is the multiset extension of the
ordering of literals (threefold multiset extension of `$<$'). Although
we have here three different orderings, we will use the same symbol `$<$' to
denote any of them. This should not introduce any confusion as the
 sets of terms, literals and clauses are disjoint.\\[8pt]
%\subsubsection
\noindent {\bf The {\sc maximal literal} proof strategy}

The
%changes
literals
mentioned explicitly in the premises of the proof rules are called
{\em active}. Various ways of selecting the active
%changes
literals will lead to
different proof strategies. The {\em maximal literal} strategy
requires that the active
%changes
literals in the premise clauses are the ones
which are maximal wrt. the ordering defined above.
Stated explicitly the strategy amounts
to the following restrictions on the application of the rules:
\begin{description}\MyLPar
\item[Reflexivity resolution:] the literal \(s\oplus s\) is maximal 
in the premise clause.
\item [Superposition:]
%changes
the atom \(s\oplus t\) and the literal \(u[s]_p\otimes v\)
are maximal in their clauses.
\item [Compositionality resolution:] the atom \(s\oplus t\) is maximal
in its clause. The atom \(s\odot u\) {\bf is not} maximal in 
the second premise clause,
but the term $s$ {\bf is} maximal in this clause,  
and the maximal literal in this clause is positive. Both \(\oplus\) and
\(\odot\) are positive.
\end{description}

%CHANGE
The restriction on the last rule is the only case where some active atom
($s\odot u$) is not maximal in its clause. However, it is almost
maximal because the maximal term $s$ of the clause occurs in it.  Another
reason why this weakening of the strategy is not essential is that 
the second
clause in the premise provides merely the context allowing application
of the rule, and in fact the atom $s\odot u$ is not so ``active''. 
A particular consequence of this restriction is that the rule can be applied only
when its second premise is a non-Horn clause.


\section{Rewriting proofs} \label{se:rewrite}

In the next section we show that if the empty clause can not be deduced using 
the maximal literal strategy, then a model exists satisfying the initial set of 
clauses. The model is constructed from an appropriate set of ground atoms 
which force all the initial clauses to be true. The notion of forcing requires 
construction of a deductive closure of a given set of literals. This section 
investigates the rewriting proofs in which ground literals are rewritten to 
ground literals. The obtained results will serve as a basis for the 
construction of forcing set in the completeness proof.

%CHANGE
Although, eventually, only atoms will be used in the model construction 
 we give
a more general account -- our definitions and lemmas
apply to rewriting with both negative and positive literals.

Rewriting of literals with the set-relations is based on the fact that the 
relations satisfy  replacement properties from Lemma~\ref 
{le:replacement-in-atoms}. For example, the implication: \(s\Int t\impl
u[s]_p \Int  u[t]_p\) means that the atom \(u[s]_p \Int u[t]_p\) can be derived 
applying the rule \(s\To\Int t\) to the term \(u[s]_p\).
%changes
%CHANGE
The following definition states what kind of literals can be derived directly 
applying the replacement property to some set \C A of ground literals (also
called {\em axioms}). 
%As a matter of fact, only atoms can be derived 
%with nontrivial applications of this property, and only such case will be
%needed in the proof of completeness. 
\begin{DEFINITION} \label{def:rewriting-step}
A literal $r$ is a {\em rewriting step} in \C A if either 1) \(r\in\C A\),
 or 2)
$r$ is an atom $u[s]_p\oplus u[t]_p$,
and  \(s\otimes t\in \C A\), where $\oplus=\otimes$, if
$\otimes\Not=\Eq$, or \(\oplus\in\{\Incl,\Cont\}\), otherwise.
\end{DEFINITION}
%CHANGE
The rule based
directly on this kind of term-rewriting is superposition.
The forcing set in the completeness proof will consist of ground 
positive literals,
which can be derived using only this one rule.
% this rule is the only rule applicable to derive from them new literals.
%changes
The superposition rule takes two rewriting steps and composes them into one. 
Consequtive applications of the superposition correspond to composition 
of the finite 
sequence of the corresponding rewriting steps \(\<s\oplus_1 t_1,\: t_1\oplus_2 
t_2,\: t_2\oplus_3t_3,\: ...\:,\:t_n\oplus_n t\>\).
Such a sequence is called a {\em rewriting sequence}, 
and the predicate sign $\oplus$ of the resulting literal is
computed using the function \(\Comp\_\_\): \(\oplus=\Comp {(\Comp {(\Comp 
{\oplus _1^{-1}}{\oplus _2})^{-1}}{\cdots })^{-1}}{\oplus _n}\). The next 
definition puts all such literals into {\em rewriting closure} of $\C A$. This 
closure also contains atoms that are trivially true.
\begin{DEFINITION}\label {def:rewriting-closure}
For a set \C A of ground literals, the {\em rewriting closure} of \C A is the set
of ground literals, $\C A^\ast$, defined as follows:
\begin{itemize}\MyLPar
\item  all atoms of the form $s\Incl s$ or $s\Int s$ belong to $\C A^\ast$;
\item if an atom \(s\oplus t\in\C A\) and a literal \(u[s]\otimes v\in\C A^\ast\),
then the literal \(u[t]\odot v\in\C A^\ast\), if 
\(\odot=\Sup(s,u[s],\oplus,\otimes)\).
\end{itemize}
\end{DEFINITION}
%changes: removed graph+what follows
%It follows from Lemma~\ref{le:replacement} that rewriting steps with equality
%predicate can not be produced by replacement. This means that equality
%steps, if they appear in proofs, are equality axioms and are
% used without replacement.
Primarily, we are interested in {\em reducing} rewriting sequences, {\em i.e.}, 
such that rewriting is used to produce terms of lower complexity in some 
well-founded ordering.  The term ordering is used to orient literals but it
does not allow us to orient the {\em reflexive} literals of the form $s\oplus s$.
%changes
%(there no sense to use other reflexive literals in rewriting sequences)
However, the orientation problem of these particular literals
turns out to be inessential for the following arguments (except the next 
definition), and so we allow them to have orientation that is appropriate for 
the context in which it is used. A literal \(s\oplus t\) can be written in the 
form \(s\To\oplus t\) to emphasize that $s\geq t$, then it is also called a {\em
rule}. The fact that this literal is derived by a rewriting sequence in which 
terms do not increase in any step is written as \(s \TTo \oplus t\) or (the 
same) as \(t \oTT{\oplus \rlap{${}^{-1}$}}s\).
\begin{DEFINITION} \label{def:reducing-proof}
A rewriting sequence is {\em reducing} (w.r.t. to an ordering of terms
$<$) if it does not contain a {\em peak}, {\em i.e.}, a pair of consecutive
rewriting steps \(s\oplus t,t\otimes u\) such that \(s\leq t\geq u\).
A {\em rewriting proof} is a reducing rewriting sequence.
\end{DEFINITION}
%CHANGE
The non-strong inequalities in the last condition capture the cases of
reflexive steps. A rewriting step \(s\oplus s\) does not form a peak
in a rewriting sequence only at a locally minimal point,
{\em i.e.}, in a rewriting proof where $s$ is the smallest term.
Definition~\ref {def:reducing-proof} means that any reducing proof consists of 
two decreasing branches like \(s\TTo{}u\oTT{}t\), or has only one \(s\TTo{}t\) 
or \(s\oTT{}t\). The table from Lemma~\ref{le:composition} can be written as a 
summary of all the possible combinations of the resulting predicate signs 
appearing in two-branches rewriting proofs:
\[\begin{array}%
 {@{(s}c@{u}c@{t\lor s}c@{u}c@{t\lor s}c@{u}c@{t)\ \impl\ s}c@{t}c}
\TTo\Eq   & \oTT\Eq   & \TTo\Eq   & \oTT\Cont & \TTo\Incl & \oTT\Eq   & \Eq   &,\\
\TTo\Eq   & \oTT\Incl & \TTo\Eq   & \oTT\Int  & \TTo\Incl & \oTT\Incl & \Incl &,\\
\TTo\Cont & \oTT\Cont & \TTo\Cont & \oTT\Eq   & \TTo\Int  & \oTT\Eq   & \Cont &,\\
\TTo\Cont & \oTT\Int  & \TTo\Cont & \oTT\Incl & \TTo\Int  & \oTT\Incl & \Int  &.
\end{array}\]
Lemma~\ref{le:replacement-in-atoms} describes how the peaks can be eliminated
from rewriting sequences. Let us take, for example, one implication from this lemma:
\(s\Int t\land u[s]\Eq v\impl u[t]\Cont v.\)
The premise can be interpreted as a possibility to have a peak \(u[t] \oT\Int
u[s] \To\Eq v \) in proofs, if both atoms \(s\Int t\) and \(u[s]\Eq t\) are
axioms. This peak can be ``cut down'' changing it by the consequence
\(u[t]\Cont v\), if it is also among the axioms. The following notions are
commonly used in similar situations. 
%
\begin{DEFINITION} \label {def:critical-atom}
A rule \(r_1 = s\To\oplus t\) {\em overlaps} a rule \(r_2 = u[s]_p \To \otimes 
v\). In this case the literal \(l = u[t]_p \odot v\), where \(\odot = 
\Sup(s,u[s]_p,\oplus,\otimes)\), is called a {\em critical literal} formed by 
the rules \(r_1,r_2\), if $l$ is different from \(r_1\) and \(r_2\).
\end{DEFINITION}
Critical literals correspond to {\em critical pairs} from equational reasoning 
\cite{Der}. In our case the definition is more complex because the predicate 
sign is important and replacement is not merely of ``equals by equals''. Also, 
when the rule \(r_1\) is
%changes
reflexive (which is not necessarily a tautology in our case) then
the critical literal $l$ may be the same as \(r_2\). It is better to exclude
such cases because they would complicate our model construction.
\begin{DEFINITION} \label{def:confluent-system}
A set \C R of ground rewriting rules is {\em confluent} if $\C R^\ast$ contains 
all critical literals formed by overlapping rules from \C R.
\end{DEFINITION}
In term-rewriting theory \cite{Der} such systems are called {\em 
locally-confluent}. Confluent systems have slightly different definition, but 
both these notions are proved to be equivalent.  In \cite{LA} a similar 
definition introduces bi-confluent systems.

In completeness proofs like ours, {\em fully-reduced} \cite{PP} or {\em
left-reduced} \cite{S-A,BG} rewriting systems are used.  We are not able to
define the analogous notion, since deduction and reduction 
% (see the proof of Theorem~\ref{th:soundness}) 
are not the same in our language, and will apply
Definition~\ref{def:confluent-system} instead. Its direct consequence is
\begin{LEMMA} \label{le:proofs-in-confluent}
Any literal derivable by a rewriting sequence in a confluent system \C R has
a rewriting proof in \C R.
\end{LEMMA}
% \begin{PROOF}
% Using induction on rewriting sequences as multisets of terms ordered by a
% multiset extension of the term ordering. 
%
% When composition of literals is stronger than replacement,
% the question may arise, why the definition of critical literals does not take in
% account these cases. The answer is that in
% these cases both rules overlap each other, and we have two possible cases.
% One of them gives the same result as one got by composition.
% \end{PROOF}

%changes
%CHANGE
Since we have allowed both negative and positive literals to occur in 
one set of axioms $\C A$,  the 
unpleasant situation, when both an atom $a$ and its negation $\neg a$ 
belong to
$\C A^\ast$, is possible. The set $\C A$ is {\em consistent} if no such 
atom 
exists. A set containing only atoms is obviously consistent. 
Although such a set will be of main importance in the following section,
we again formulate stronger results, 
taking into account the general situation of possibly inconsistent
sets of literals.
%sets of that kind are considered in the rest of the paper, we
%present here more general results than we need further.
Next lemma, to be used in the completeness proof to construct confluent 
systems incrementally, characterizes rules that can be added to 
a confluent and consistent system preserving both these properties.
Here we  have again the situation different  from the usual 
equational reasoning, because
%changes
the rule \(s\Eq t\) overlaps itself and produces the critical atom \(t \Eq t\) 
which need not be always true. 

\begin{LEMMA} \label{le:preserve-confluency}
For a confluent and consistent system \C R and a rule $r\notin\C R^\ast$ the 
system \(\C R\cup \{r\}\) is confluent and consistent iff
%changes
\newITEM{coco}
\ITEM{triv}{$r$ does not have the form  \(s\To\oplus s\), where
 \(\oplus\in\{\notIncl,\notCont,\notInt\}\),}
\ITEM{critical}{ for any critical literal $l$ formed by any $r'\in \C R
%changes
\cup\{r\}
$ overlapping (or overlapped by) $r$, $l\in \C R^\ast$,}
\end{LEMMA}
%
%changes: new proof
%\begin{PROOF} We first prove a simpler case --- that the lemma conditions
%imply
%\ITEM{simpler}{\(\neg r\notin\C R^\ast\),}
%and later will show that the general case is reducible to this one. Unfolding
%rewriting closure Definition~\ref {def:rewriting-closure} we get from
%\?{simpler} that either
%\ITEM{refl}{$\neg r$ has the form $s\Incl s$ or $s\Int s$, or}
%\ITEM{crit}{there are an atom $s\oplus t\in \C R$ and a literal \(l=
%   u[s]\otimes v\in\C R^\ast\) such  that \(\neg r=u[t]\odot v\), where \(\odot
%   =\Sup (s,u[s],\oplus,\otimes )\).}
%The case \?{refl} is excluded by \?{triv}. In the case of
%\?{crit} we may assume \(u[t]>v\) and \(t\geq s\), because the rewriting
%sequence deriving \(\neg r\) must be reducing. By \?{critical}, the critical literal
%\(u[s]\ominus v\) produced by $r$ and the rule \(t\oplus^{-1} s\) belongs to
%\(\C R^\ast\), here \(\ominus=\Sup(t,u[t],\oplus^{-1},\neg\odot)\). This
%critical literal exists, because \?{crit} means implication \(s\oplus t \land
%l \impl \neg r\), which is equivalent to \(s\oplus t \land r \impl \neg
%l\). In most cases \(\neg l=u[s]\ominus v\), {\em i.e.}, \(\neg \otimes
%=\ominus\), but sometimes the predicate \(\ominus\) may be stronger than
%\(\neg\otimes\). Both cases contradict consistency of $\C R$:  in the first one
%both \(\neg l\) and $l$ are in \(\C R^\ast\), in the second one the rewriting
%sequence \(\<v\ominus ^{-1} u[s], u[s]\otimes v\>\) proves one of literals
%\(v\notIncl v\) or \(v\notInt v\).
%
%Let now consider the general case: both some atom \(a= u\oplus v\) and its
%negation \(\neg a=u(\neg\oplus)v\) are in \((\C R\cup\{r\})^\ast\). Assume that
%$a$ is minimal. If \(u>v\), then concatenation of rewriting sequences deriving
%\(v\oplus^{-1} u\) and \(u(\neg\oplus)v\) gives the sequence proving the
%literal \(v\notIncl v\) (check Table~\ref {tbl:composition}) that is smaller
%than $a$. So, \(v=u\). Let assume
%\ITEM{noteq}{ \(\oplus\ne\Eq\).}
%The atom $a$ is in the rewriting closure by definition, and $r$ is used only in
%the proof of \(\neg a\). Since \(\C R\cup \{r\}\) is obviously confluent,
%\(\neg a\) has a rewriting proof. If it consists of two branches \(u\TTo{} z\) and
%\(z\oTT{} u\) with \(z<u\), then the sequence \(z\oTT{}u\TTo{} z\) (with
%these branches interchanged) derives \(z\notInt z\) or \(z\notIncl
%z\). To be sure in that is enough to check nine cases in Table~\ref
%{tbl:composition}. Both atoms are smaller than $a$, what contradicts minimality
%of $a$.
%
%In ``flat'' rewriting sequences (whit all steps being reflexive
%literals) nontrivial rewriting steps are only \(u\Eq u\) and \(u\notEq u\).
%One of these literals must be $r$, the another must belong to \C R.
%
%In the opposite case to \?{noteq}, the similar consideration based on
%minimality of atom $a$ shows that both literals  \(a=u\Eq u\) and \(\neg a=u\notEq u\)
%must have ``flat'' proofs. Only in this case proof branches are not
%interchanged, but composed with the sequence proving another literal. In the case
%of ``flat'' proofs $r$ is $a$ or \(\neg a\), so \(\neg r\in\C R\).
%\end{PROOF}

Finally, we merely register the following technical result to be used in the next section.
\begin{LEMMA} \label {le:first-rule}
%changes
Let \C R be a confluent and consistent system of ground literals, \(a\in \C R\)
and \(b\in\C R^\ast\) be literals, \(b\leq a\) and $b$ can not be derived
without $a$. Then $a$ and $b$ have the same maximal term, say $s$, and, if $P$
is a rewriting proof of $b$ in $\C R$, then the rule $a$
in $P$ rewrites $s$ and is used only once in $P$,
{\em i.e.}, \(P=\<a,P'\>\), where $a$ is not used in $P'$. If \(a\Not= b\), 
then the literal \(c\), proved by the rest $P'$ of the proof $P$, 
is smaller than $b$.
\end{LEMMA}

%\end{document}

