\documentclass[11pt]{article}
\usepackage{amssymb}

\makeatletter
%\voffset -2cm
\input{a4wide}
\makeatother

\input defs
\newcommand\der{{\,\Rightarrow\,}}
\newcommand{\togo}[1]{{\tiny{#1}}\normalsize}
\newcommand{\leadto}{\mathrel{\rightsquigarrow}}

\newcounter{BIB}
\newcommand{\bibyear}[1]{#1}
\newcommand{\bibemph}[1]{{\em #1}}
\newcommand{\bibemphic}[1]{{\em #1}}
\newcommand{\bibsc}[1]{{\sc{#1}}}

\input xypic
%\xyoption{graph}
\xyoption{frame}

\title{Sets, Nondeterminism, Initiality and \ldots Junk}
\author{Micha{\l} Walicki
\and Sigurd Meldal}


\begin{document}

\maketitle
\abstract{By means of examples we show that nondeterminism should be distinguished
from underspecification. The latter does not provide sufficient means of abstraction,
in particular, in the presence of unordered structures and iteration over such 
structures. We then point out that nondeterminism subsumes underspecification and,
consequently, attempts at desinging initial semantics of nondeterminism lead to 
undesirable consequences introducing, what we call, ``intuitive junk'' into 
models.
}


\section{Introduction}
There is no need to argue for the plausibility of the initial semantics. 
It has immediate intuitive appeal in that it establishes a very close relation 
between the syntax of a specification and its semantics. Initial semantics is 
essentially syntactic, as reflected in the names ``term model'' or ``word model''. 
Initiality implies that the semantic changes induced by syntactic changes in a 
specification are minimal, and so reflect the latter in the natural and expected 
manner. For instance, adding a new sort and a constant of this sort has no exotic 
influence on the model. The model will be extended with a new sort and just the 
one element needed for interpretation of the new constant. Also, writing different 
terms one usually intends them to be distinct entities unless they are explicitly 
equated with other terms. 

The two slogans expressing these properties of initial models are ``no junk'' and 
``no confusion'' - no element appears in the model whose existence is not required 
by the interpretation of terms introduced in the specification, and distinct terms 
are interpreted as distinct elements unless their identity follows from the equations 
of the specification. In short, initiality is nice because it gives intuitive models, 
and the two slogans make the notion of ``intuitive'' more precise.

A limitation of the initial approach is that not all theories have initial models. 
It is well known \cite{c:76, c:78, c:122} %[10,8,14] 
that Horn theories are the most general theories always 
possessing initial models. As the interest in initial semantics was carried over to 
the domain of nondeterministic specifications, so was the interest in Horn theories.

In the first part of the paper we give an argument motivating the use of 
nondeterminism in specification. In particular, we emphasize the difference between
nondeterminism and underspecification. Roughly, the argument boils down to the 
observation that unordered structures, in particular sets, are very common and
often most convenient data structures -- both in specification and programming. 
Equally common is the need for iteration
over such structures. But iteration introduces implicit ordering! We show by means of
an example that the correct iterator over unordered structures is nondeterministic
choice and that iteration along some implicitly assumed ordering, in spite of apparent
plausibility, can easily lead to unintended results.

The second part of the paper illustrates the consequences of applying the 
theory of initiality 
to the domain of nondeterminism. We point out two general ways
of introducing nondeterminism into specification and exemplify them by means of
multialgebras \cite{c:53, c:Hes, c:58, c:59, c:64} %[3,4,7] 
and unified algebras \cite{c:91, c:92}. %[11,12]. 
A simple, yet illustrative, example is worked out in these formalisms leading to
some general observations\footnote{The example itself was used in \cite{c:91}, but has 
certainly been contemplated by 
anybody devoting a few minutes' thought to nondeterminism. We are particularly 
thankful to Vladimir Antimirov for his comments and discussion of it in the context 
of unified algebras.}:
since nondeterminism subsumes 
underspecification, the initial models of nondeterminism introduce ``intuitive junk'' 
and, furthermore, that treating nondeterministic specification not merely as 
underspecification but as specification of (truly) nondeterministic operations 
does not make the situation worse.

The presentation focuses on the concepts and general phenomena rather than technicalities. 
We give the definitions of multialgebraic and unified algebra semantics but the paper aims at
rather informal presentation. More technical details can be found in \cite{survey,BW97}.
In particular, the issue of formal reasoning with the specifications of nondeterminsm
is not addressed at all -- the reader is referred to \cite{c:130,c:69, c:69a}. 
% Then we suggest that the way to avoid the 
%implausibilities is simply to allow the specifier to say what he intends to say.

\section{Why Nondeterminism?}\label{se:why}
One of the aims of specifying a program is to express its functionality at an 
abstract level, avoiding complications implied by operational and implementation 
details. Abstract properties of the intended structure may allow different 
implementations, and one should avoid overspecifying the problems as this may 
exclude some, otherwise acceptable, implementations. 

The traditional means of abstraction in algebraic specifications is 
underspecification. The choice it leaves one between different models is often
either confused with nondeterminism or else meant to be a sufficient surrogate.
We begin with a few remarks on this issue and then preoceed to with an example
illustrating that nondeterminism may be an appropriate abstraction mechenism in writing 
specifications which cannot be replaced by underspecification.

%\section{Underspecification vs. nondeterminism}
\subsection{Underspecification vs. nondeterminism}\label{sub:underA}
% Limiting a language to Horn 
% formulae may restrict the possibility of assuming such a ``don't care'' attitude. 
The choice operation may serve as a (paradigmatic) example: assume that we want an 
operation $\ch:S\times S\into S$ which, for arguments $a,b$, should equal 
either $a$ or $b$. A possible underspecification might be:
%The only way 
%to capture this intention without using disjunction is to leave $c$ partly specified 
%or unspecified. For instance:
\[\begin{array}{rrrr@{\ \into\ }l}
SP= & \Sorts: & \multicolumn{2}{l}{S} \\
 & \Funcs: &  a,b: & & S \\
 &   & \ch: & S\times S & S \\
 & \Ax: & \multicolumn{3}{l}{
 \begin{array}[t]{rrcl}
1.& x\ch x& = & x \\
2.& x\ch y& = & y\ch x \\
3.& x\ch (y\ch z)& = & (x\ch y)\ch z 
\end{array} }
\end{array}
\]
where $a, b$ are the two intended elements of sort $S$. Axioms 1.-3. 
assert general properties of $\ch$ as join. 
Underspecification means that the specification possesses several nonisomorphic 
models, and all of them are taken as the semantics of the specification. $SP$ will 
allow models where $a\ch b = a$, and others where $a\ch b = b$. But in 
general, loose 
semantics will admit structures which violate the demands of ``no junk'' 
and ``no confusion''. Not only will $SP$ have models where $a=b$, but also such where 
 $a\ch b$ returns neither $a$ nor $b$. 

The operation $\ch$ has only a remote resemblance to 
the choice operation. To get something closer to choice, one might add 
the axiom $x\ch y= x\lor x\ch y= y$. It would, however, exclude the 
possibility of defining initial semantics -- we discuss it in the 
subsequent section. 

But there are other problems with ignoring nondeterminism and replacing it by mere 
underspecification. In \cite{c:132} the known impossibility of implementing 
underspecified sets with the choice operation by sequences with the head 
operation was discussed in detail -- it was shown how this problem can be 
solved using nondeterminism instead of underspecification. Here, we will 
illustrate another general point indicating the insufficiency of 
deterministic specifications when dealing with sets. To do that, we first 
introduce a few basic concepts from the multialgebraic framework for 
specification of nondeterminism.

The problem of nondeterminism consists in defining 
precisely the relationship between the arguments $x$ and $y$ and the 
result of $x\ch y$ -- the latter, to be a choice, {\em must} equal one of 
the two. We want the operation $\ch$ to
behave like choice and not like a yet another constructor. That is, we may have
usual deterministic operations constructing, possibly, new elements and, in addition, 
nondeterministic operations which, however, return only elements constructed by other
means. This relationship is captured by a multilagebra where 
nondeterministic operations are modeled by set-valued function.

\subsection{Multialgebras}\label{sub:multA}
A multialgebra (over a usual signature $\Sigma$) is a $\Sigma$-algebra where
operations return not necessarily individual elements but, possibly, sets thereof.
Following \cite{c:127, c:126}, we use two primitive predicates for building 
atomic formulae: $s\Eq t$ says that $s$ and $t$ denote the same, {\em one-element} set, 
and $s\Incl t$ that the set interpreting $s$ is included in that interpreting $t$.
\begin{DEFINITION}\label{de:mult}
A $\Sigma$-multialgebra $A$ is given by:
\begin{enumerate}\MyLPar
\item for each sort symbol $S$, the carrier set $S^A$
\item for each operation symbol $f:S_1...S_n \into S$, an operation
$f^A:S_1^S...S_N^A\into \PSet(S^A)$
\end{enumerate}
Given a $\Sigma$-term $t$ (with variables $X$), any assignment $\alpha:X\into A$ 
of {\em individual} elements from the
carrier of $A$ to $X$, induces a unique interpretation $\ovl\alpha(t)$ of $t$ in $A$.

The formulae of specifications are built from the atomic equalities and inclusions, and
are of the form $a_1,...,a_n\Seq b_1,...,b_m$, with atomic $a_i$ and $b_j$.
$A$ satisfies a formula $\phi$ under assignment $\alpha$
\begin{enumerate}\setcounter{enumi}{2}\MyLPar
\item $A\models_\alpha s\Eq t$ iff $\ovl\alpha(s)=\ovl\alpha(t)=\{e\}$ for some
$e\in A$;
\item $A\models_\alpha s\Incl t$ iff $\ovl\alpha(s)\subseteq\ovl\alpha(t)$;
\item $A\models_\alpha a_1,...,a_n\Seq b_1,...,b_m$ iff $\exists 
1\leq i\leq n : A\not\models a_i$ or $\exists 1\leq j\leq m:A\models b_m$.
\end{enumerate}
$A\models\phi$ iff $A\models_\alpha\phi$ for all $\alpha$.
\end{DEFINITION}

\noindent
$\PSet(X)$ denotes the set of non-empty subsets of $X$.
2. makes it possible for a constant $c:\ \into S$ to denote a {\em set} of
elements from $S^A$. Also, according to 3. $s\Eq t$ holds iff both terms denote the
same 1-element set and not just the same set. Variables are assigned {\em individual} 
and not sets.\footnote{Motivations for these choices can be found
in \cite{c:126, c:132}.}

Now, consider the following specification
\[\begin{array}{rrrr@{\ \into\ }l}
SPN= & \Sorts: &\multicolumn{2}{l}{E} \\
 & \Funcs: & a,b,c: & & E \\
 &   & \ch: & E\times E & E \\
 & \Ax: & \multicolumn{3}{l}{
 \begin{array}[t]{rrcl@{\hspace*{5em}}rrcl}
1.& z\Incl x\ch y & \Impl & z\Eq x, z\Eq y  &  3.& a & \Eq & a  \\
2.& c & \Incl & a\ch b  &  4.& b & \Eq & b  \\
&  &  &  &  5.& c & \Eq & c  
\end{array} }
\end{array}
\]
Axioms 3.-5. ensure merely that the constants are deterministic, i.e., denote individual
elements. $x\ch y$ is now a nondeterministic operation which returns, either $x$ or $y$
-- whenever $z$ is a result of $x\ch y$, then either $z\Eq x$ or $z\Eq y$.
The constant $c$, on the other hand, is not nondeterministic -- axiom 5. It is, however,
underspecified -- in any model it will denote one element, either the same as denoted by
$a$ or this denoted by $b$.

\subsection{Nondeterministic choice is the iterator for sets}\label{sub:iter}
Graphs are typically represented as sets of vertices and sets of edges. Operations
on graphs involve then naturally operations on sets. In particular, many graph
algorithms perform iteration over these sets. 

As an example, let us consider the problem of
constructing the depth-first traversal tree of nodes reachable from a particular node of 
a directed, irreflexive graph. We assume that a (connected) graph $g$, represented
as a pair $\<V,N\>$, where $V$ is a set of vertices and $N:V\into\PSet(V)$ is an 
operation returning, for every vertex $v$ the set of its neighbours. Working with sets, 
we also assume some standard specification thereof, in particular, operations
empty set, $\es:\ \into S$, adding an element to a sets, $+:S\times E\into S$ and 
removing an element $\setminus: S\times E\into S$. 
%(We will allow ourselves to apply these to single
%elements, treating them as 1-element sets.)

The following attempts to specify the standard algorithm for $DFS(g,v)$ starting 
from the vertex $v$ in a graph $g$ and constructing the DFS-tree by the recursive
calls to operation $Tr:G\times V\times S\into S$, where $S$ is a set of edges 
representing the tree constructed so far.
\[\begin{array}{rrcl}
1.& DFS(g,v) & = & Tr(g,v,\es) \\
2.& N(g,v)=\es & \Impl & Tr(g,v,t)=t \\
3.& N(v)=S+x, x\in |t| & \Impl & Tr(g,v,t)= Tr(g\setminus\<v,x\>,v,t) \\
4.& N(v)=S+x, x\not\in |t| & \Impl & Tr(g,v,t)= 
  Tr(g\setminus\<v,x\>,v,\  Tr(g\setminus\<v,x\>,x,t+\<v,x\>)\ )
\end{array}
\]
The construction starts with the empty tree (axiom 1). If $v$ has no neighbours (either
because all were visited/marked or because $v$ is a leaf), $Tr$ backtracks (axiom 2).
If $v$'s neighbour $x$ is marked (indicated by $x\in |t|$, i.e., $x$ is among the
vertices included in $t$) the edge $\<v,x\>$ is removed from $g$ (axioms 3). If,
on the other hand the neoghbour $x$ was not visited before, the edge $\<v,x\>$ is
removed from $g$ and added to $t$, and the construction proceeds recursively down
through $x$ (axiom 4).

This corresponds hopefully to the intuitive understanding of the algorithm and
may look plausible -- but only as long as we do not inspect the sort of sets.
Sets are unordered and so, for instance, adding elements to a set should be
commutative:
\begin{equation}
 S+x+y  =  S+y + x
\end{equation}
But then we will also obtain:
\begin{equation}
Tr(g+\<v,b\>+\<v,a\>, v,\es) = Tr(g+\<v,a\>+\<v,b\>, v, \es)
\end{equation}
In other words, for a graph:

$g = \vcenter{\xymatrix @R=2ex @C=1ex{ 
% & \save*{v}*\cir<5pt>{}\restore \ar[dl]\ar[dr] \\ 
& v \ar[dl]\ar[dr] \\  a\ar[rr] & &  b}}$
we will get the equality of the DFS-trees: 
$\vcenter{\xymatrix @R=2ex @C=1ex{ & v \ar[dl]\ar[dr] \\ a & &  b}}\ =\ 
 \vcenter{\xymatrix @R=2ex @C=1ex{ & v \ar[dl] \\ a\ar[rr] & &  b}}$. 

\noindent
The problem is that the internal structure of the set values intrudes into the 
specification. The definition of $Tr$ in terms of adding elements to a set tries, on
the one hand, to respect the representation of graphs in terms of sets (of neighbours
of each vertex) and, on the other hand, use the ordering of sets, implicit in their
definition by means of adding elements.
One might avoid the problem by specifying the $DFS$ choosing representation of 
graphs, in particular, the neighbours $N(v)$ to be sequence. This, however, is
quite contrary to the central tenet of (algebraic) specifications -- they should 
capture only the essential properties and should not relay on the 
representation/implementation details.

An abstract definition of $DFS$ should {\em not} force the implementor to construct
a given particular DFS-tree but, on the contrary, determine the necessary requirements
leaving the choice of a particular strategy (here particular way of ordering a set)
to the implementor. This is achieved by the following, nondeterministic variant of the
above specification. We assume the same representation of graphs and specification
of sets as before. In addition, we have the nondeterministic choice operation
$\ch:S\into E$ satisfying, at least, the axiom $S\Eq\es\lor\ch(S)\in S$.
\[\begin{array}{rrcl}
1.& DFS(g,v) & \Incl & Tr(g,v,\es) \\
2.& N(g,v)\Eq \es & \Impl & Tr(g,v,t)\Eq t \\
3.& x\Incl \ch(N(v)), x\in |t| & \Impl & Tr(g,v,t)\Incl Tr(g\setminus\<v,x\>,v,t) \\
4.& x\Incl \ch(N(v)), x\not\in |t| & \Impl & Tr(g,v,t)\Incl 
  Tr(g\setminus\<v,x\>,v,\  Tr(g\setminus\<v,x\>,x,t+\<v,x\>)\ )
\end{array}
\]
Operation $Tr$ is now capable of returning any (all) DFS-trees -- depending on the
choice of $x$ from the set $N(v)$ at each stage (axiom 4). Instead of the
unintended collapse of diffferent trees, we will now have that:
\[
Tr( \vcenter{\xymatrix @R=2ex @C=1ex{ 
& v \ar[dl]\ar[dr] \\  a\ar[rr] & &  b}}, v,\es)\ \Incl\ \{
\vcenter{\xymatrix @R=2ex @C=1ex{ & v \ar[dl]\ar[dr] \\ a & &  b}},\ 
 \vcenter{\xymatrix @R=2ex @C=1ex{ & v \ar[dl] \\ a\ar[rr] & &  b}}\ \} 
\]
The example illustrates the point that deterministic specification may, 
unavoidably, amount to {\em overspecification} thus violating the central 
objective of algebraic specifications. As we said, this is just one 
example of a situation which is likely to occur whenever the involved 
data structures are inherently unordered.

\section{Initiality + Nondeterminism $\Impl$ Junk}
The success of initial semantics for deterministic specifications motivates -- or, 
could we perhaps say, motivated? -- the 
search for such semantics also for the specifications involving nondeterminism. 

A conservative approach would use nondeterminism merely for the purpose of 
underspecification and hope that initiality in classes of models of such specifications 
would retain the purity expected  of traditional initial models. We will 
now argue that, 
from the point of view of the initial semantics, the sole problem of nondeterminism 
is caused by the fact that it subsumes underspecification. Nondeterminism in itself 
does not cause much harm - it is the fact that deterministic operations can be 
underspecified by means of nondeterministic ones that leads to some intuitive flaws 
in the initial models.


The initial model of $SP$ from \ref{sub:underA} will contain 
\[\begin{array}{c@{\ }|@{\ \ }c@{\ \ \ \ }c}
x       & \ini(x) \\ \hline
a       & a   \\
b       & b   \\
a\ch b	& a\ch b  \\
a\ch a	& a   \\
\multicolumn{2}{c}{\ldots}
\end{array}
\]
The problematic point is the presence of the element $a\ch b$. Formally, this is quite 
correct since the corresponding term exists in the specification and is not provably 
equal to $a$ or $b$. However, with respect to the original intention it represents junk, 
since $a$ and $b$ were supposed to generate all the elements of the sort $S$. We may 
call this ``intuitive junk'' to distinguish it from unreachable elements corresponding 
to (formal) junk. It may appear in a carelessly written specification, but here it 
appears because of the insufficiently expressive language.

Initial semantics requires one to restrict the language to Horn clauses. 
Hence, one cannot add the axiom $x\ch y = x \lor x\ch y= y$ to get rid of 
the unintended element $a\ch b$. 
Thus, due to the limitations of language, underspecification gives us a choice 
between an imprecisely defined class of models or intuitive junk.


Nondeterminism can be introduced into a language in two basic ways: either 
by means of some new primitive relation/predicate 
(set membership, inclusion) allowing specification of nondeterministic operations,
or else by 
including some primitive operation (choice) with predefined semantics reflecting 
the intended nondeterminism. 
The former is exemplified by multialgebras and in \ref{sub:multB} we make some
further remarks on this approach. As an example of the latter, we have chosen 
unified algebras and present them in \ref{sub:ua}. 


\subsection{Multialgebras}\label{sub:multB}
The intention to obtain initial model requires one to restrict, unlike in 
definition~\ref{de:mult}, the
language to conditional formulae (or, if necessary, Horn clauses). 
A work motivated by this intention was \cite{c:58, c:59}. We merely summarise the
main points of this approach which will allow us to make the relevant observations.
The specification $SPN$ from \ref{sub:multA} used disjunction to specify the choice
operation. If we remove the constant $c$, and axioms 2. and 5., the specification
will have an initial multialgebraic model but this is just a lucky coincidence. In 
general, disjunction does not admit initial models. Let us therefore exclude disjunctions
-- a corresponding specification might be as follows:
\[\begin{array}{rrrr@{\ \into\ }l}
SPNI= & \Sorts: &\multicolumn{2}{l}{E} \\
 & \Funcs: & a,b,c: & & E \\
 &   & \ch: & E\times E & E \\
 & \Ax: & \multicolumn{3}{l}{
 \begin{array}[t]{rrcl@{\hspace*{5em}}rrcl}
1.& x &\Incl & x\ch y  &  3.& a & \Eq & a  \\
2.& x &\Incl & x\ch y   &  4.& b & \Eq & b  \\
3.& c & \Incl & a\ch b &  5.& c & \Eq & c  
\end{array} }
\end{array}
\]
It has initial model, constructed from the term multistructure $T_\Sigma:$
\[\begin{array}{r@{\ =\ }l@{\hspace*{4em}}r@{\ =\ }l}
 \ini(a) & \{a\}  & \ini(a\ch b) & \{a,b,c\} \\
\ini(b) & \{b\} & \ini(a\ch c)& \{a,c\} \\
\ini(c) & \{c\} & \ini(b\ch c) & \{b,c\} \\
{\rm for\ other\ }s,t\in T_\Sigma: \ini(s\ch t) & \ini(s)\cup\ini(t)
\end{array}
\]
As we can see, $\{c\}$ appears in the initial model as an additional
element. As far as choice is concerned, the axioms 1. and 2. do make it into
set union (in the initial model), but the underspecified $c$ gives rise to 
the ``intuitive junk''. This phenomemenon is by no means limited to this particular
way of using multialgebras -- it is the unavoidable side-effect of marrying 
nondeterminsm (with the possibility of underspecification) with initiality.

In fact, to guarantee the existence of initial multimodels the restriction to 
Horn clauses is not sufficient. Hu{\ss}mann specified other, sufficient (and slightly 
restrictive but not unreasonable) conditions. Since they do not make the 
`'intuitive junk'' disappear, we will not elaborate on them here.


\subsection{Unified algebras}\label{sub:ua}
Unified algebras have been introduced by Peter Mosses in \cite{c:91,c:92}.%[11,12]. 
In the following discussion the definitions and notation for unified algebras
 have been modified to be consistent with the rest of the paper.

Every unified signature $\Sigma$ contains the subsignature $\Omega$  with the 
operations $\{{\sf nothing}, \_|\_, \_\&\_\}$ and predicates 
$\{\_=\_, \_\leq\_, \_:\_\}$. For the sake of 
notational compatibility we will use the notation 
$\{\bot, \_\sqcap\_, \_\ch\_\}$ and $\{\_=\_, \_\Incl\_, \_:\_\}$. 
Formulae of the specifications can be (universal) Horn clauses. A unified 
$\Sigma$-algebra A is a structure (with one sort) such that:
\begin{itemize}\MyLPar
\item $A$ is a distributive lattice with $\sqcap^A$ as join, $\ch^A$ as meet, 
   and $\bot^A$ as bottom.
\item There is a distinguished set $E^A\subseteq A$ - the individuals  of $A$.
\item $=^A$ is the identity on the elements of the lattice (not only on the individuals).
\item $\Incl^A$ is the partial order of the lattice, i.e., 
   $x\Incl^A y\Iff x\sqcap^Ay=^Ay$.
\item For every $f\in\Sigma$, $f^A$ is monotone wrt. $\Incl$.
\item $x:^Ay$ holds iff $x\in E^A$ and $x\Incl^A y$
\end{itemize}
``Unified'' refers to the fact that sorts (just like individuals) are elements of 
the lattice and not sets of the elements as in the case of multialgebras. The partial 
order of the lattice corresponds to set inclusion, and nondeterministic choice is 
interpreted as joins. As we can see, nondeterministic choice is here a predefined
operation -- join, whose semantics is built into the framework.

The operations from $\Omega$ can be specified using Horn clauses alone, and it is shown 
that specifications with Horn clauses always possess initial unified models. 
The example specification becomes:
\[\begin{array}{rrrr@{\ \into\ }l}
SPU= & \Funcs: & \multicolumn{3}{l}{a,b,c} \\
 & \Ax: & \multicolumn{3}{l}{
 \begin{array}[t]{rrcl@{\hspace*{5em}}rrcl}
1.& a & : & a  \\
2.& b & : & b   \\
3.& c & : & a\ch b 
\end{array} }
\end{array}
\]
(Since unified algebras have only one sort there is no need to specify profiles 
of the operations, except for the number of arguments they take.) 
The first axioms make $a$ and $b$ individuals. 
The third one makes $c$ an individual which, in addition, lies below the join 
$a\ch b$. The intended meaning of this is to have two individuals, 
$a$ and $b$, and to let $c$ be a result of choosing non-deterministically between 
the two.   
But again, having $c$ as a constant in the signature, one may expect to find it also 
in the initial model. However, since any model must be a (distributive) lattice, 
there are more surprises than that. The initial unified algebra for 
$SPU$ is given by the following figure:
\[
\xymatrix @R=2.5ex @C=2ex {
 & & a\ch b \ar@{-}[dl] \ar@{-}[dr] \ar@{-}[dd]\\
& a\ch c \ar@{-}[dl] \ar@{-}[dr] & & b\ch c \ar@{-}[dl] \ar@{-}[dr]  \\
a \ar@{-}[d] & & % \save*{(a\meet c)\ch(b\meet c)}*\frm<5pt>{-}\restore 
(a\ch c)\meet(b\ch c)
  \ar@{-}[dll]\ar@{-}[drr]\ar@{-}[dl]\ar@{-}[dd]
     & & b \ar@{-}[d] \\
a\meet(b\ch c) \ar@{-}[dr]\ar@{-}[drr] & c\ar@{-}[d]\ar@{-}[drr] &  & & 
     (a\ch c)\meet b \ar@{-}[dl] \ar@{-}[dll] \\
& a\meet c \ar@{-}[dr] & a\meet b \ar@{-}[d] & b\meet c \ar@{-}[dl] & \\
& & a\meet b\meet c \ar@{-}[d] & & \\
& & \bot & & 
}
\]
Most of the elements of ths model are surprises which we would not expect, and
definitely did not intend, when writing the specification $SPU$.
 They have to appear because the lattice model requires all joins and meets to be 
present and they are irreducible with the lattice axioms alone.\footnote{For the 
purpose of modeling nondeterminism the meets are not needed and the upper 
semi-lattice would provide sufficient structure. This would give a significantly more 
intuitive model - see (the upper part of) the next figure. Nevertheless, even for 
such a simple example, junky c and its joins would remain.}
We can get rid of some of the ``vacuous sorts'' by introducing additional axioms. 
In the present case, the axiom 
\begin{equation}
a\meet b =\bot  \label{eq:addua}
\end{equation}  will identify most of the 
redundant elements leading to the following, more intuitive model:
\[
\xymatrix @R=2.5ex @C=2ex {
 & & a\ch b \ar@{-}[dl] \ar@{-}[dr] \ar@{-}[dd]\\
& a\ch c \ar@{-}[dl] \ar@{-}[dr] & & b\ch c \ar@{-}[dl] \ar@{-}[dr]  \\
a \ar@{-}[dr] & & [c]  \ar@{-}[dl]\ar@{-}[dr]\ar@{-}[dl]\ar@{-}[dd]
     & & b \ar@{-}[dl] \\
& [a\meet c] \ar@{-}[dr] &  & [b\meet c] \ar@{-}[dl] & \\
& & [\bot] & & 
}
\]
Here, $c$ is still a separate element which cannot be set equal to $a$ nor $b$. 
Consequently, the respective joins and meets must be present as well, although 
we know that one from each pair will actually collapse (e.g., if $c$ is equal to $a$ 
then $a\ch c=a\meet c=a$). We can give some plausibility to the presence of 
joins - not knowing 
whether $c$ is $a$ or $b$, we do not know whether $a\ch c$ is going to be 
$a$ or $a\ch b$, i.e., we 
have to keep both. Thus, in general, even after spending time and effort on 
finding out which additional axioms are needed to remove irrelevant elements, we 
will be left with some redundant objects in the initial model. 
As before, the removal of the axiom$c:a\ch b$ underspecifying $c$ would lead to 
the intended  initial model with the elements $\{a,b,a\ch b,a\ch b,\bot\}$.
 
There is another aspect of the ``redundancy'' in the context of unified algebras. 
Even if we do not specify explicitly the choice operator, it will be present in the 
model. In the above example we only said that $c$ should be a result of $a\ch b$ and 
the elements corresponding to $a\ch c$ and $b\ch c$ have been included in the model, 
so to speak, automatically. This is, of course, a consequence of the fact that 
choice is a primitive operator and  appears in all the approaches we have seen 
where its semantics is built into the general framework. 

\section{Comparison}
We emphasize some points concerning the relations between the models we 
have examined. One should keep in mind that these particular models were chosen 
merely as examples of two ways of approaching nondeterminism, the one insisiting
on the interpretation in terms of sets and their elements (multialgebras), the other
attempting to fix the semantics of choice in an appropriate mathematical structure
(unified algebras). The remarks apply to these respective classes.

It is easy to see that the upper part of the second lattice from~\ref{sub:ua} is 
essentially the same as the initial multimodel from~\ref{sub:multB}, 
where the partial order is specialized to set inclusion. 
In particular, the ``redundant'' elements $c, \{a,c\}, \{b,c\}$ are present in 
the multimodel as they are in the unified algebra. Certainly, the advantage 
of the multimodel is that it is obtained directly, while unified algebras 
required an additional axiom (\ref{eq:addua}). 
On the other hand, unified algebras guarantee the existence of initial models for 
all specifications with Horn clauses, while only a subclass of Horn specifications 
possess initial multimodels.
Nevertheless, even these `` natural'' models involve elements which are superfluous 
when compared to the intentions of the specifier. 
 
Treating choice as a primitive of the language with predefined semantics is plausible in 
so far as choice is a very natural nondeterministic operation which will typically 
be present in specifications using nondeterminism. Although in the initial multimodel 
of $SPNI$ choice happens to be join, this will not be the case in general. In other 
(non-generated) multimodels $a\ch b$ may return all other kinds of elements besides
 $a$ and $b$.  Thus, all models of $SPNI$ will satisfy 
$a\ch c\Incl a\ch (a\ch b)$, but not necessarily $a\ch c\Incl a\Incl b$. 
The latter simply does not hold in the 
models where $a\ch c$ returns some elements not returned by $a\ch b$. 
This, of course, does not happen in the unified algebra models for which 
nondeterminism cannot be defined by the user.

Nevertheless, it is precisely this 
predefined meaning of $\ch$ in unified algebras which is responsible for the 
occurrence of ``junk'' which, to some extent, can be eliminated by additional axioms.
Multialgebras, on the other hand, do not restrict the user in this respect 
but give him the possibility of explicitly specifying the join operator if there 
is a need for it. Inclusion of the axioms 4.-6. from $SP$ (section~\ref{sub:underA})
into $SPMI$, i.e., two new axioms with inclusions per one equational axiom from $SP$, 
would make $\ch$ into join and result in the validity of $a\ch c\Incl 
a\ch b$. 
This gives increased flexibility  
since each nondeterministic operator can be specified directly - in 
particular, when no such operations are present, multialgebra reduces 
essentially to a standard algebra. In unified algebras, on the other hand, 
all nondeterminism must be referred back to the primitive choice operator 
which is always present in the model.
Concluding our examples we can just repeat the sequence of implications:
\begin{center}
nondeterminism $+$ initiality  $\leadto$  underspecification $+$ initiality  
$\leadto$  junk.
\end{center}
The superfluous objects may or may not have some intuitive plausibility but are not 
among the objects usually intended by the writer of the specification. 
This is only an empirical statement and we do not claim to have proved that all 
initial models which can possibly be produced in the future are doomed to contain 
``junk''. But, as a matter of fact, all approaches of this kind, including unified 
algebras, rewriting logic \cite{c:87} and other models based on partial orders, e.g. \cite{c:77}, 
do share this feature.
It is reasonable to expect that a high degree of sophistication may be needed in 
order to cope with the problems indicated by the above examples. Even if one succeeds 
in eliminating junk, the result may lack the simplicity of the original initial 
semantics of deterministic specifications.

The examples indicate that the amount of redundancy is less in multialgebras than in 
the other models. However, the existence of initial multialgebras is guarded by 
most restrictive conditions. Unified algebras specified with Horn formulae always
 posses initial models, but the occurrence, and the character, of redundant elements 
in such models is difficult for a human being to determine from the specification 
text alone. 
Initiality is certainly a virtue, but an even greater virtue is the adequacy of 
the model. It seems that, in the case of nondeterminism, the intuitive 
appeal of the ``no junk'' property
of initial models gets lost. Even worse --  
initiality becomes a powerful ally of intuitive junk in the semantics of 
nondeterministic specifications.

\section{Disjunction \& Quasi-Initiality}
The constructions motivated by the search for the initial semantics attempt 
to indicate that $c$ is equal to $a$ or $b$, as is the intention of the specification, 
without actually identifying $c$ with any of the two: the source ``intuitive junk'' in all the 
examples was the $c$ element. One wants to model the fact that $c=a$ or $c=b$ without 
spelling it clearly out.  This fear originates, of course, in the knowledge that 
disjunctive equations do not, in general, allow initial models. 

The source of evil lies in the fact that nondeterminism allows us to 
underspecify $c$, while one still insists on using initial models of such specifications. 
Deterministic 
underspecifications give rise to similar problems. However, in the deterministic 
case underspecification is an optional tool for handling exceptional situations rather 
than the standard procedure. Typically, one tries to apply some strategy, such as 
generator induction \cite{c:28, c:44,c:60}, %[1,2,5], 
resulting in specifications with intended initial models. 
Nondeterminism, on the other hand, implies disjunction and, with it, underspecification.
 
Another aspect of this implication is that the nondeterministic operations themselves
 are not adequately specified. In all  cases, underspecification of the 
 $c$ element, combined with initiality,
destroyed $a\ch b$ as the binary choice and turned it into an operation capable of 
returning, besides $a$ and $b$, some $c$. These observations make us argue that making a 
clear distinction between nondeterminism and underspecification and admitting 
disjunctive formulae, like in $SPN$ in \ref{sub:multA}, to handle the latter is 
more advantageous than it is dangerous. 
Above all, it allows us to restore the intended simplicity of the model. 

Introducing the lattice structure in unified algebras, one avoids disjunction and 
models it with the help of the join operation. It might seem that, since disjunction 
is the join operation (in the Boolean algebra of propositions), the two will lead to 
similar results. However, the obvious differences are quite significant:
\begin{center}
\begin{tabular}{c@{\ \ }|@{\ \ }c}
Lattice/Joins & Disjunctive specification \\ \hline
all joins must be present & only relevant disjunctions are included \\
introduces ``junk'' & eliminates ``junk'' \\
allows initial models & disallows initial models
\end{tabular}
\end{center}
%\noindent
The first point refers to the fact that in the lattice model join is an 
operation (choice) with predefined semantics. If there are several constants in 
the specification $SPU$, say $d$ besides $a, b$ and $c$, then unified algebra is 
forced to interpret the element $a\ch d$ as join. But if we are interested in a 
binary operation which is only some variation of choice, e.g., chooses 
nondeterministically merely between $a$ and $b$, and for other arguments behaves 
as, say first projection, then we have to relate it to the primitive choice
 operation. $a\ch d$ will always be there. Disjunction allows us to specify 
different kinds of nondeterministic (also partially defined) operations without 
any reference to some basic form of nondeterminism. 

So, we may treat disjunction as a replacement of the join operation. It will not 
lead to the lattice models but, instead, to the standard algebraic models, that is, multimodels. The most 
important advantage of this is that it actually removes the unintended ``junk'' 
and produces the models (in the initial coverings) which have an intuitive clarity 
comparable to initial models of deterministic specifications. We could (under)specify 
our example as it was done in $SPN$ in \ref{sub:multA}. 
To make a final comment on the issue of nondeterminism vs. underspecification, let's
modify it slightly
\[\begin{array}{rrrr@{\ \into\ }l}
SPN2= & \Sorts: &\multicolumn{2}{l}{E} \\
 & \Funcs: & a,b,c: & & E \\
 &   & \ch: & E\times E & E \\
 & \Ax: & \multicolumn{3}{l}{
 \begin{array}[t]{rrcl@{\hspace*{4em}}rrcl}
1.& z\Incl x\ch y & \Impl & z\Eq x \lor z\Eq y  &  3.& a & \Eq & a  \\
2.& && c\Eq a  \lor  c\Eq b &  4.& b & \Eq & b  \\
&  &  &  &                5.& c & \Eq & c 
\end{array} }
\end{array}
\]
Axiom 1. specifies binary choice by underspecifying each particular {\em application} 
of it. It reads: if $z$ is a result of (some) application of $x\ch y$ then $z$ equals 
$x$ or $y$. 
% (Compare this to the axiom 2. from $SP$.) 
% Substituting $d, a, b$ for $z,x,y$ and using axiom 1. we will get that $d$ equals $a$ 
% or $b$.
Axiom 2., on the other hand, does not make $c$ a nondeterministic operation but merely
underspecifies it to be either $a$ or $b$.
The difference between an underspecified $c$ and a nondeterministic operation $\ch$ 
is that the former has a unique value in every model, but these values  may vary 
from one model to another. The latter, on the other hand, may also return different 
values in one model.  
$a\ch b$ may be thought of as a series of distinct applications, each returning 
either $a$ or $b$. That is, $c$ is underspecified, so to speak, once for 
all, while it is every single {\em application} of $a\ch b$ that
is underspecified! Thus
\begin{center}
\begin{tabular}{r@{\ \ }c@{\ \ }l}
nondeterminism & $\not=$ & underspecification \\
nondeterminism & $=$  & underspecification of each application
\end{tabular}
\end{center}
% The difference between $d$ and $c$ is that $c$ is underspecified independently from 
% $\ch$, while possible interpretations of $d$ in a given model are determined by the
% interpretation of $\ch$.
%Notice that the choice operator is actually not needed at all. Disjunction allows 
%us to distinguish c as underspecified in SPD from d as a result returned by 
%nondeterministic choice in SPD1 below (although we are not going into the 
%details here - see [15]). 
%
The price is, of course, that $SPN2$ no longer has an  initial model.
 Nevertheless, disjunction does not spoil 
initiality completely. We have shown that, in the presence of mild restrictions, 
disjunctive specifications do possess quasi-initial multialgebra semantics \cite{c:127}. %[15]. 
Quasi-initiality generalizes initiality to the situations involving 
``either ... or ...''. For $SPN2$, such a semantics can be summarized by saying 
that the model class will consist of two parts: the models where $c$ equals 
$a$ and those where it equals $b$; $a\ch b$ will always contain, 
at least, both $a$ and $b$. The quasi-initial semantics is given by the 
following two multimodels which are  initial in the 
respective components of the model class:
\[\begin{array}{c|cc}
 & A & B  \\ \hline
a & a & a  \\
b & b & b  \\
a\ch b & \{a,b\} & \{a,b\} \\
c  & a & b
\end{array}
\]

\section{Conclusions}
We have argued that nondeterminism provides adequate means for specifying 
operations on inherently unordered structures. In particular, 
nondeterministic choice is the natural operation for performing iteration 
over sets. In such context, deterministic specifications are bound to 
overspecify the operations and nondeterminism is simply the adequate 
abstraction mechanism.

The traditional abstraction mechanism -- underspecification -- is 
different from nondeterminism and cannot perform its function.
The former amounts to underspecifying a given operation requiring, 
nevertheless, its result to be unique in every model. Nondeterminism, on 
the other hand, allows one operation to return different results within 
the same model. It can be thought of as underspecification not of an 
operation itself but of its particular applications.

We argued that the suggested initial semantics of 
nondeterminism, although resulting possibly in elegant mathematical 
models, suffer from intuitive flaws -- in the context of
nondeterminsm such a semantics does not have intuitive purity and appeal 
which made it so convincing in the case of deterministic specifications. 
In particular, it loses the connection between the argument set and the 
results which are supposed to come from this set. This real, and 
intuitive, connection is the crux of nondeterminism and it seems to be 
most adequately represented by multialgebras. The price is that one can 
no longer obtain initial semantics in general situation. As a possible 
alternative, we indicated the quasi-initial semantics.

\bibliographystyle{bibNo}
\bibliography{my}


\end{document}

REFERENCES
[1]	Dahl, O.J., Verifiable Programming,  Prentice Hall, 1992.
[2]	Guttag, J.V., The Specification and Application to Programming of ADT, Tech. Rep., CSR6-59, Computer Systems Research Group, University of Toronto 1975.
[3]	Hesselink, W.H., ``A Mathematical Approach to Nondeterminism in Data Types'', ACM: Transactions on Programming Languages and Systems, vol. 10, 1988.
[4]	Hußmann, H., Nondeterministic Algebraic Specifications, Ph.D. thesis, Fakultät für Mathematik und Informatik, Universität Passau, 1990.
[5]	Huet, G., Hullot, J., ``Proofs by Induction in Equational Theories with Constructors'', JCSS, vol. 25, 239-266, 1981.
[6]	Kaplan, S., ``Rewriting with a Nondeterministic Choice Operator'', Theoretical Computer Science, vol. 56, 37-57, 1988.
[7]	Kapur, D., Towards a theory of abstract data types, Ph.D. thesis, Laboratory for CS, MIT, 1980.
[8]	Mahr, B., Makowsky, J.A., ``Characterizing specification languages which admit initial semantics'', in Proc. 8th CAAP, vol. 159, LNCS, Springer, 1983, pp. 300-316.
[9]	Maibaum, T.S.E., The Semantics of Nondeterminism, Tech. Rep., CS-77-30, University of Waterloo, Ontario, Canada December 1977.
[10]	Makowsky, J.A., ``Why Horn Formulas Matter in Computer Science'', Journal of Computer and System Science, vol. 34, 266-292, 1987.
[11]	Mosses, P.D., ``Unified Algebras and Action Semantics'', in STACS'89, vol. 349, LNCS, Springer, 1989.
[12]	Mosses, P.D., Unified Algebras and Institutions, Tech. Rep., DAIMI PB-274, CS Dep., Aarhus University 1989.
[13]	Subrahmanyam, P.A., ``Nondeterminism in Abstract Data Types'', in Automata, Languages and Programming, vol. 115, LNCS, Springer, 1981.
[14]	Tarlecki, A., ``Free constructions in algebraic institutions'', in Mathematical Foundation of Computer Science '84, vol. 176, LNCS, Springer, 1984.
[15]	Walicki, M., Meldal, S., ``Equality in Specifications of Nondeterminism'' [submitted for publication]; also available in Walicki, M., Calculii for nondeterministic specifications: three completeness results, Tech. Rep., 75, Institutt for Informatikk, Universitetet i Bergen December 1992.



\end{document}




